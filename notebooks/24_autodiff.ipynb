{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic differentiation of RNA circuit dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cuda(id=0), cuda(id=1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import optax\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import diffrax as dfx\n",
    "from typing import List\n",
    "\n",
    "from functools import partial\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from bioreaction.simulation.simfuncs.basic_de import one_step_de_sim_expanded\n",
    "\n",
    "jax.config.update('jax_platform_name', 'gpu')\n",
    "\n",
    "if __package__ is None:\n",
    "\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "    __package__ = os.path.basename(module_path)\n",
    "\n",
    "\n",
    "os.environ['EQX_ON_ERROR']='breakpoint'\n",
    "os.environ['JAX_DISABLE_JIT']='1'\n",
    "\n",
    "np.random.seed(0)\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synbio_morpher.srv.parameter_prediction.simulator import make_piecewise_stepcontrol\n",
    "from synbio_morpher.utils.misc.type_handling import flatten_listlike\n",
    "from synbio_morpher.utils.modelling.physical import eqconstant_to_rates, equilibrium_constant_reparameterisation\n",
    "from synbio_morpher.utils.modelling.deterministic import bioreaction_sim_dfx_expanded\n",
    "from synbio_morpher.utils.modelling.solvers import get_diffrax_solver, make_stepsize_controller, simulate_steady_states\n",
    "from synbio_morpher.utils.results.analytics.timeseries import calculate_adaptation, compute_peaks, compute_adaptability_full\n",
    "from bioreaction.simulation.simfuncs.basic_de import bioreaction_sim, bioreaction_sim_expanded, one_step_de_sim_expanded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_species_bound(species_unbound):\n",
    "    return sorted(set(flatten_listlike([['-'.join(sorted([x, y])) for x in species_unbound] for y in species_unbound])))\n",
    "\n",
    "\n",
    "# RNA circuit settings\n",
    "species_unbound = ['RNA_0', 'RNA_1', 'RNA_2']\n",
    "species_bound = make_species_bound(species_unbound)\n",
    "species = species_unbound + species_bound\n",
    "species_signal = ['RNA_0']\n",
    "species_output = ['RNA_2']\n",
    "# species_output = ['RNA_1', 'RNA_2']\n",
    "species_nonsignal = [s for s in species_unbound if s not in species_signal]\n",
    "idxs_signal = np.array([species.index(s) for s in species_signal])\n",
    "idxs_output = np.array([species.index(s) for s in species_output])\n",
    "idxs_unbound = np.array([species.index(s) for s in species_unbound])\n",
    "idxs_bound = np.array([species.index(s) for s in species_bound])\n",
    "signal_onehot = jnp.array([1 if s in idxs_signal else 0 for s in np.arange(len(species))])\n",
    "signal_onehot_inv = (signal_onehot == 0) * 1.0\n",
    "\n",
    "# Circuit parameters\n",
    "n_circuits = 20\n",
    "n_circuits_display = 30\n",
    "key = random.PRNGKey(0)\n",
    "N0 = 200\n",
    "y00 = np.array([[N0] * len(species_unbound) + [0] * len(species_bound)]).astype(np.float32)\n",
    "y00 = np.repeat(y00, repeats=n_circuits, axis=0)\n",
    "\n",
    "# Dynamic Simulation parameters\n",
    "k_a = 0.00150958097\n",
    "signal_target = 2\n",
    "t0 = 0\n",
    "t1 = 500\n",
    "ts = np.linspace(t0, t1, 500)\n",
    "tmax = 1000\n",
    "dt0 = 0.005555558569638981\n",
    "dt1_factor = 5\n",
    "dt1 = dt0 * dt1_factor\n",
    "max_steps = 16**4 * 10\n",
    "use_sensitivity_func1 = False\n",
    "sim_method = 'Dopri8'\n",
    "stepsize_controller = 'adaptive'\n",
    "threshold_steady_state = 0.01\n",
    "batch_size = 20\n",
    "n_steps = 1000                   # Number of optimization steps\n",
    "\n",
    "# Reactions\n",
    "energies = random.normal(key, (n_circuits, len(np.tril_indices(len(species_unbound))[0])))\n",
    "energies = np.interp(energies, (energies.min(), energies.max()), (-25, 0))\n",
    "eqconstants = jax.vmap(partial(equilibrium_constant_reparameterisation, initial=N0))(energies)\n",
    "forward_rates, reverse_rates = eqconstant_to_rates(eqconstants, k_a)\n",
    "forward_rates = forward_rates[0]\n",
    "\n",
    "inputs = np.array([\n",
    "    [2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
    "], dtype=np.float64)\n",
    "outputs = np.array([\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODE functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_func = partial(bioreaction_sim_dfx_expanded,\n",
    "                   t0=t0, t1=t1, dt0=dt0,\n",
    "                   forward_rates=forward_rates,\n",
    "                   inputs=inputs,\n",
    "                   outputs=outputs,\n",
    "                   solver=get_diffrax_solver(sim_method),\n",
    "                   stepsize_controller=make_stepsize_controller(t0, t1, dt0, dt1, choice=stepsize_controller))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_s(deriv, y, y0):\n",
    "    # return - jnp.divide(jnp.power(y - y0, 2), y0)\n",
    "    return deriv * jnp.power(jnp.divide(y - y0, y0), 2)\n",
    "\n",
    "\n",
    "def obj_p(y, y0):\n",
    "    # return jnp.divide(jnp.power(y - y0, 2), y0)\n",
    "    return jnp.power(jnp.divide(y - y0, y0), 2)\n",
    "\n",
    "\n",
    "def objective_sp(s, p, ttot, idxs_output):\n",
    "    s_objective = (s ** 2)[..., idxs_output].sum() / ttot\n",
    "    p_objective = - (p ** 2)[..., idxs_output].sum() / ttot\n",
    "    return s_objective + p_objective\n",
    "\n",
    "\n",
    "def simulate_signal(y0, reverse_rates):\n",
    "    sol = partial(sim_func, return_as_sol=True, \n",
    "                  saveat=dfx.SaveAt(ts=jnp.linspace(t0, t1, 500), dense=True))(\n",
    "        y0=y0, reverse_rates=reverse_rates)\n",
    "    ddy_dt = jax.vmap(sol.derivative)(sol.ts)\n",
    "    y_sens = obj_s(ddy_dt, sol.ys, y0)\n",
    "    y_prec = obj_p(sol.ys, y0)\n",
    "    return sol.ts, (sol.ys, ddy_dt, y_sens, y_prec)\n",
    "\n",
    "\n",
    "def simulate(y0, params):\n",
    "    \"\"\" (y11, ddys1, y_sens, y_prec) = ys1 \"\"\"\n",
    "    ts0, ys0 = jax.vmap(sim_func)(y0=y0, reverse_rates=params)\n",
    "    y01 = (jnp.array(ys0[:, -1]) * signal_onehot * signal_target) + (jnp.array(ys0[:, -1]) * signal_onehot_inv)\n",
    "    # y01[:, idxs_signal] = signal_target * y01[:, idxs_signal]\n",
    "    ts1, ys1 = jax.vmap(simulate_signal)(y0=y01, reverse_rates=params)\n",
    "    # (y11, ddys1, y_sens, y_prec) = ys1\n",
    "    return (ts0, ys0), (ts1, ys1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise ODE sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise = False\n",
    "\n",
    "if visualise:\n",
    "    y0 = y00[:10]\n",
    "    params = reverse_rates[:10]\n",
    "\n",
    "    (ts0, ys0), (ts1, ys1) = simulate(y0, params)\n",
    "    (y11, ddys1, y_sens, y_prec) = ys1\n",
    "\n",
    "    n_plots=6\n",
    "    plt.figure(figsize=(5*n_plots, 5))\n",
    "    titles = ['y', 'ddy', 'y_sens', 'y_prec']\n",
    "    i_circ = 5\n",
    "    for i, title in enumerate(titles):\n",
    "        ax = plt.subplot(1, n_plots, i+1)\n",
    "        plt.plot(ts, ys1[i][i_circ, :, idxs_output].T)\n",
    "        plt.title(title)\n",
    "        plt.legend(species_output)\n",
    "    ax = plt.subplot(1, n_plots, 5)\n",
    "    plt.plot(ts, (ys1[2][i_circ, :, idxs_output].T * ys1[3][i_circ, :, idxs_output].T))\n",
    "    plt.title('y_sens * y_prec')\n",
    "    plt.legend(species_output)\n",
    "\n",
    "    ax = plt.subplot(1, n_plots, 6)\n",
    "    plt.plot(ts, ((ys1[1] ** 2)[i_circ, :, idxs_output].T * ys1[3][i_circ, :, idxs_output].T))\n",
    "    plt.legend(species_output)\n",
    "    plt.title('ddy^2 * y_prec')\n",
    "\n",
    "    print(y_sens.sum()/ t1, y_prec.sum()/t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualise:\n",
    "    ts = jnp.concatenate([ts0, ts1 + ts0.max()], axis=1)[0]\n",
    "    ys = jnp.concatenate([ys0, ys1[0]], axis=1)\n",
    "    loss = jax.vmap(partial(objective_sp,\n",
    "                            ttot=t1-t0, idxs_output=idxs_output))(y_sens, y_prec)\n",
    "\n",
    "    nr = int(np.ceil(np.sqrt(len(params))))\n",
    "    nc = int(np.ceil(np.sqrt(len(params))))\n",
    "\n",
    "    plt.figure(figsize=(5*nc, 5*nr))\n",
    "    for i in range(len(params)):\n",
    "        plt.subplot(nr, nc, i+1)\n",
    "        plt.plot(ts1[0], y11[i][..., idxs_output])\n",
    "        \n",
    "        plt.title(f'Circuit {i}: loss = {loss[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the ODE function\n",
    "# def ode_func(t, y, params):\n",
    "#     return params.sum(axis=-1) - y  # (y * params).sum(axis=-1) - y\n",
    "\n",
    "\n",
    "# def smooth_max(a, b, epsilon=1e-2):\n",
    "#     \"\"\" Smooth approximation for maximum \"\"\"\n",
    "#     return epsilon * jnp.log(jnp.exp(a / epsilon) + jnp.exp(b / epsilon))\n",
    "\n",
    "\n",
    "# def smooth_max2(a, b):\n",
    "#     \"\"\" Smooth maximum approximation using softplus\"\"\"\n",
    "#     return jnp.log1p(jnp.exp(a - b)) + b  # Softplus-based approximation\n",
    "\n",
    "\n",
    "# def max_value_ode(t, y, args):\n",
    "#     \"\"\" `args` is a tuple (params, max_val) \"\"\"\n",
    "#     params, epsilon = args\n",
    "#     max_val = y[1]\n",
    "#     dy_dt = ode_func(t, y[0], params)\n",
    "#     # max_val = jnp.max(jnp.vstack([max_val, y[0]]), axis=0)\n",
    "#     max_val = smooth_max(max_val, y[0], epsilon)\n",
    "#     # return dy_dt, jnp.sin(y[0])\n",
    "#     return dy_dt, max_val\n",
    "\n",
    "\n",
    "# def ode_sp(t, y, args):\n",
    "#     params, y0 = args\n",
    "#     # y_t, y_sens, y_prec = y\n",
    "#     y_t = y\n",
    "#     dy_dt = sim_func(t, y_t, args, reverse_rates=params)\n",
    "#     y_sens = obj_s(dy_dt, y_t, y0)\n",
    "#     y_prec = obj_p(y_t, y0)\n",
    "#     return dy_dt #, y_sens, y_prec\n",
    "\n",
    "\n",
    "# # Modified function to solve the ODE and track the maximum value with params\n",
    "# def solve_ode_and_track_max(y0, params, t0, t1, dt0, dt1, stepsize_controller, max_steps=1000, idx_output=-1):\n",
    "\n",
    "#     # Solve the ODE with an auxiliary variable to track the max\n",
    "#     solution = dfx.diffeqsolve(\n",
    "#         dfx.ODETerm(ode_sp),\n",
    "#         solver=get_diffrax_solver(sim_method),\n",
    "#         t0=t0,\n",
    "#         t1=t1,\n",
    "#         dt0=dt0,\n",
    "#         y0=y0,\n",
    "#         # y0=(y0, y0, y0),\n",
    "#         args=(params, y0),  # Pass params and initial max as args\n",
    "#         saveat=dfx.SaveAt(ts=jnp.linspace(t0, t1, max_steps)),\n",
    "#         stepsize_controller=make_stepsize_controller(t0, t1, dt0, dt1,\n",
    "#                                                      choice=stepsize_controller)\n",
    "#         # adjoint=dfx.BacksolveAdjoint()  # This enables differentiation\n",
    "#     )\n",
    "\n",
    "#     y_sens, y_prec = solution.ys[1][-2:]  # Get the max value reached\n",
    "#     return solution, y_sens[idx_output], y_prec[idx_output]\n",
    "\n",
    "\n",
    "# def solve_naive(y0, params, t0, t1, dt0, max_steps=10000, idx_output=-1):\n",
    "\n",
    "#     y, y_sens, y_prec = y0, y0, y0\n",
    "#     # , np.zeros((max_steps, len(y0))), np.zeros((max_steps, len(y0)))\n",
    "#     ys, ys_sens, ys_prec = np.zeros((3, max_steps, len(y0)))\n",
    "#     for i_t, tstep in enumerate(np.linspace(t0, t1, max_steps)):\n",
    "#         dy_dt, y_sens, y_prec = ode_sp(\n",
    "#             tstep, (y, y_sens, y_prec), (params, y0))\n",
    "#         y = y + dy_dt * dt0\n",
    "#         ys[i_t] = y\n",
    "#         ys_sens[i_t] = y_sens\n",
    "#         ys_prec[i_t] = y_prec\n",
    "#     return ys, ys_sens, ys_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def loss_fn(params, y0, t0, t1):\n",
    "    \"\"\" Define a loss function to optimize params \"\"\"\n",
    "    (ts0, ys0), (ts1, ys1) = simulate(y0, params)\n",
    "    (y11, ddys1, y_sens, y_prec) = ys1\n",
    "\n",
    "    loss = jax.vmap(\n",
    "        partial(objective_sp, ttot=t1-t0, idxs_output=idxs_output)\n",
    "        )(y_sens, y_prec)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# @jax.jit\n",
    "def batch_loop(params_b, y0b, t0, t1, optimiser, opt_state):\n",
    "\n",
    "    loss_b, grads_b = jax.value_and_grad(\n",
    "        partial(loss_fn, t0=t0, t1=t1))(params_b, y0b)\n",
    "    updates, opt_state = optimiser.update(grads_b, opt_state)\n",
    "    params_b = optax.apply_updates(params_b, updates)\n",
    "\n",
    "    return loss_b, grads_b, params_b\n",
    "\n",
    "\n",
    "# @jax.jit\n",
    "def optimise_step(params, opt_state, y0, t0, t1, optimiser, batch_size):\n",
    "    def extend_batch(xs, xsb):\n",
    "        if xs is None:\n",
    "            xs = xsb\n",
    "        else:\n",
    "            xs = jnp.concatenate([xs, xsb])\n",
    "        return xs\n",
    "\n",
    "    loss, grads = (None, None)\n",
    "    for batch_step in range(0, len(params), batch_size):\n",
    "        print(f\"Batch step: {batch_step}/{len(params)}\")\n",
    "        i0, i1 = batch_step, batch_step + batch_size\n",
    "        params_b, y0b = (params[i0:i1], y0[i0:i1])\n",
    "\n",
    "        loss_b, grads_b, params_b = batch_loop(\n",
    "            params_b, y0b, t0, t1, optimiser, opt_state)\n",
    "\n",
    "        params = jax.ops.index_update(params, jax.ops.index[i0:i1], params_b)\n",
    "        loss = extend_batch(loss, loss_b)\n",
    "        grads = extend_batch(grads, grads_b)\n",
    "    return params, opt_state, loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Batch step: 0/20\n"
     ]
    }
   ],
   "source": [
    "params = reverse_rates\n",
    "\n",
    "# Set up optax optimiser\n",
    "optimiser = optax.adam(learning_rate=0.01)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "# Optimization loop\n",
    "loss_all = np.zeros(n_steps)\n",
    "grads_all = np.zeros((n_steps, len(params)))\n",
    "for i in range(n_steps):\n",
    "    print(f'Step {i}')\n",
    "    params, opt_state, current_loss, current_grads = optimise_step(\n",
    "        params, opt_state, y00, t0, t1, optimiser, batch_size)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i}, Loss: {current_loss}, Params: {params}\")\n",
    "\n",
    "print(f\"Optimized Params: {params}\")\n",
    "\n",
    "# solution_steps, y_sens, y_prec = solve_ode_and_track_max(\n",
    "#     ode_func, y00, t0, t1, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Max's\n",
    "x1 = jnp.ones(10) * 2.\n",
    "x2 = jnp.linspace(0, 2, 10)\n",
    "max_val = smooth_max(x1, x2, epsilon=1e-1)\n",
    "# max_val = smooth_max2(x1, x2)\n",
    "max_val, jnp.maximum(x1, x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
